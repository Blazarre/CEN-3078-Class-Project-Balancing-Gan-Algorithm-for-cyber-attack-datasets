{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Running Import Statements and ensuring GPU Support"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "16bc02c3fb613f07"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-14T23:48:38.920448700Z",
     "start_time": "2024-04-14T23:48:33.852847800Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import glob \n",
    "from IPython.display import clear_output\n",
    "import os \n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "tf.config.list_physical_devices('GPU')\n",
    "gpu = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpu[0], True)\n",
    "print(gpu[0], \"\\n\")\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Loading the Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6dbd3b980448fb21"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "        flow_duration  Header_Length  Protocol Type  Duration          Rate  \\\n0            0.000000          54.00           6.00     64.00      0.329807   \n1            0.000000          57.04           6.33     64.00      4.290556   \n2            0.000000           0.00           1.00     64.00     33.396799   \n3            0.328175       76175.00          17.00     64.00   4642.133010   \n4            0.117320         101.73           6.11     65.91      6.202211   \n...               ...            ...            ...       ...           ...   \n437357       0.086171       31001.00          17.00     64.00   8560.772402   \n437358       0.000000           0.00          46.53     63.36      2.591956   \n437359       5.636653         108.00           6.00     64.00      0.354820   \n437360       0.000000          54.00           6.00     64.00     18.172690   \n437361       0.024897       16025.00          17.00     64.00  12864.464043   \n\n               Srate  Drate  fin_flag_number  syn_flag_number  \\\n0           0.329807    0.0             True            False   \n1           4.290556    0.0            False            False   \n2          33.396799    0.0            False            False   \n3        4642.133010    0.0            False            False   \n4           6.202211    0.0            False             True   \n...              ...    ...              ...              ...   \n437357   8560.772402    0.0            False            False   \n437358      2.591956    0.0            False            False   \n437359      0.354820    0.0            False             True   \n437360     18.172690    0.0            False            False   \n437361  12864.464043    0.0            False            False   \n\n        rst_flag_number  ...        Std  Tot size           IAT  Number  \\\n0                  True  ...   0.000000     54.00  8.334383e+07     9.5   \n1                 False  ...   2.822973     57.04  8.292607e+07     9.5   \n2                 False  ...   0.000000     42.00  8.312799e+07     9.5   \n3                 False  ...   0.000000     50.00  8.301570e+07     9.5   \n4                 False  ...  23.113111     57.88  8.297300e+07     9.5   \n...                 ...  ...        ...       ...           ...     ...   \n437357            False  ...   0.000000     50.00  8.312382e+07     9.5   \n437358            False  ...   8.802696    586.68  8.368106e+07     9.5   \n437359            False  ...   0.000000     54.00  8.298588e+07     9.5   \n437360            False  ...   0.000000     54.00  8.306725e+07     9.5   \n437361            False  ...   0.000000     50.00  8.301542e+07     9.5   \n\n         Magnitue     Radius   Covariance  Variance  Weight  \\\n0       10.392305   0.000000     0.000000      0.00  141.55   \n1       10.464666   4.010353   160.987842      0.05  141.55   \n2        9.165151   0.000000     0.000000      0.00  141.55   \n3       10.000000   0.000000     0.000000      0.00  141.55   \n4       11.346876  32.716243  3016.808286      0.19  141.55   \n...           ...        ...          ...       ...     ...   \n437357  10.000000   0.000000     0.000000      0.00  141.55   \n437358  34.343416  12.489157  1117.089932      0.07  141.55   \n437359  10.392305   0.000000     0.000000      0.00  141.55   \n437360  10.392305   0.000000     0.000000      0.00  141.55   \n437361  10.000000   0.000000     0.000000      0.00  141.55   \n\n                     label  \n0         DDoS-RSTFINFlood  \n1            DoS-TCP_Flood  \n2          DDoS-ICMP_Flood  \n3            DoS-UDP_Flood  \n4            DoS-SYN_Flood  \n...                    ...  \n437357      DDoS-UDP_Flood  \n437358  Mirai-greeth_flood  \n437359       DoS-SYN_Flood  \n437360      DDoS-TCP_Flood  \n437361       DoS-UDP_Flood  \n\n[10287724 rows x 47 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>flow_duration</th>\n      <th>Header_Length</th>\n      <th>Protocol Type</th>\n      <th>Duration</th>\n      <th>Rate</th>\n      <th>Srate</th>\n      <th>Drate</th>\n      <th>fin_flag_number</th>\n      <th>syn_flag_number</th>\n      <th>rst_flag_number</th>\n      <th>...</th>\n      <th>Std</th>\n      <th>Tot size</th>\n      <th>IAT</th>\n      <th>Number</th>\n      <th>Magnitue</th>\n      <th>Radius</th>\n      <th>Covariance</th>\n      <th>Variance</th>\n      <th>Weight</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.000000</td>\n      <td>54.00</td>\n      <td>6.00</td>\n      <td>64.00</td>\n      <td>0.329807</td>\n      <td>0.329807</td>\n      <td>0.0</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>54.00</td>\n      <td>8.334383e+07</td>\n      <td>9.5</td>\n      <td>10.392305</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00</td>\n      <td>141.55</td>\n      <td>DDoS-RSTFINFlood</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.000000</td>\n      <td>57.04</td>\n      <td>6.33</td>\n      <td>64.00</td>\n      <td>4.290556</td>\n      <td>4.290556</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>2.822973</td>\n      <td>57.04</td>\n      <td>8.292607e+07</td>\n      <td>9.5</td>\n      <td>10.464666</td>\n      <td>4.010353</td>\n      <td>160.987842</td>\n      <td>0.05</td>\n      <td>141.55</td>\n      <td>DoS-TCP_Flood</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000000</td>\n      <td>0.00</td>\n      <td>1.00</td>\n      <td>64.00</td>\n      <td>33.396799</td>\n      <td>33.396799</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>42.00</td>\n      <td>8.312799e+07</td>\n      <td>9.5</td>\n      <td>9.165151</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00</td>\n      <td>141.55</td>\n      <td>DDoS-ICMP_Flood</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.328175</td>\n      <td>76175.00</td>\n      <td>17.00</td>\n      <td>64.00</td>\n      <td>4642.133010</td>\n      <td>4642.133010</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>50.00</td>\n      <td>8.301570e+07</td>\n      <td>9.5</td>\n      <td>10.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00</td>\n      <td>141.55</td>\n      <td>DoS-UDP_Flood</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.117320</td>\n      <td>101.73</td>\n      <td>6.11</td>\n      <td>65.91</td>\n      <td>6.202211</td>\n      <td>6.202211</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>...</td>\n      <td>23.113111</td>\n      <td>57.88</td>\n      <td>8.297300e+07</td>\n      <td>9.5</td>\n      <td>11.346876</td>\n      <td>32.716243</td>\n      <td>3016.808286</td>\n      <td>0.19</td>\n      <td>141.55</td>\n      <td>DoS-SYN_Flood</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>437357</th>\n      <td>0.086171</td>\n      <td>31001.00</td>\n      <td>17.00</td>\n      <td>64.00</td>\n      <td>8560.772402</td>\n      <td>8560.772402</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>50.00</td>\n      <td>8.312382e+07</td>\n      <td>9.5</td>\n      <td>10.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00</td>\n      <td>141.55</td>\n      <td>DDoS-UDP_Flood</td>\n    </tr>\n    <tr>\n      <th>437358</th>\n      <td>0.000000</td>\n      <td>0.00</td>\n      <td>46.53</td>\n      <td>63.36</td>\n      <td>2.591956</td>\n      <td>2.591956</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>8.802696</td>\n      <td>586.68</td>\n      <td>8.368106e+07</td>\n      <td>9.5</td>\n      <td>34.343416</td>\n      <td>12.489157</td>\n      <td>1117.089932</td>\n      <td>0.07</td>\n      <td>141.55</td>\n      <td>Mirai-greeth_flood</td>\n    </tr>\n    <tr>\n      <th>437359</th>\n      <td>5.636653</td>\n      <td>108.00</td>\n      <td>6.00</td>\n      <td>64.00</td>\n      <td>0.354820</td>\n      <td>0.354820</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>54.00</td>\n      <td>8.298588e+07</td>\n      <td>9.5</td>\n      <td>10.392305</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00</td>\n      <td>141.55</td>\n      <td>DoS-SYN_Flood</td>\n    </tr>\n    <tr>\n      <th>437360</th>\n      <td>0.000000</td>\n      <td>54.00</td>\n      <td>6.00</td>\n      <td>64.00</td>\n      <td>18.172690</td>\n      <td>18.172690</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>54.00</td>\n      <td>8.306725e+07</td>\n      <td>9.5</td>\n      <td>10.392305</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00</td>\n      <td>141.55</td>\n      <td>DDoS-TCP_Flood</td>\n    </tr>\n    <tr>\n      <th>437361</th>\n      <td>0.024897</td>\n      <td>16025.00</td>\n      <td>17.00</td>\n      <td>64.00</td>\n      <td>12864.464043</td>\n      <td>12864.464043</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>50.00</td>\n      <td>8.301542e+07</td>\n      <td>9.5</td>\n      <td>10.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00</td>\n      <td>141.55</td>\n      <td>DoS-UDP_Flood</td>\n    </tr>\n  </tbody>\n</table>\n<p>10287724 rows × 47 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_path = '/archive/'          # If your dataset is within your python project directory, change this to the relative path to your dataset\n",
    "path = os.getcwd() + rel_path   # If your dataset is somewhere else, change this to that path\n",
    "csv_filepaths = glob.glob(os.path.join(path, \"*.csv\"))  # Makes a list of all CSVs within the directory above\n",
    "\n",
    "csv_filepaths = csv_filepaths[:40]\n",
    "\n",
    "# Features that hold values 0/1.\n",
    "column_datatypes = { 'fin_flag_number': 'bool', 'syn_flag_number': 'bool', 'rst_flag_number': 'bool',\n",
    "                     'psh_flag_number': 'bool', 'ack_flag_number': 'bool', 'ece_flag_number': 'bool',\n",
    "                     'cwr_flag_number': 'bool', \n",
    "                     'HTTP': 'bool', 'HTTPS': 'bool', 'DNS': 'bool', 'Telnet': 'bool', 'SMTP': 'bool',\n",
    "                     'SSH': 'bool',  'IRC': 'bool',   'TCP': 'bool', 'UDP': 'bool',    'DHCP': 'bool',\n",
    "                     'ARP': 'bool',  'ICMP': 'bool',  'IPv': 'bool', 'LLC': 'bool'\n",
    "                   }\n",
    "\n",
    "# Load the first csv file\n",
    "df = pd.read_csv(csv_filepaths[0]).astype(column_datatypes)\n",
    "\n",
    "# Load csv files in 10-file batches \n",
    "batch_size = 10\n",
    "\n",
    "for i in range(1, len(csv_filepaths)):\n",
    "    clear_output(wait=False) # Pretty output\n",
    "    print(f'Loading CSV {i}')\n",
    "    \n",
    "    # First file of each batch, restart the batch list\n",
    "    if i % batch_size == 1:\n",
    "        batch = [df]\n",
    "    \n",
    "    batch.append(pd.read_csv(csv_filepaths[i]).astype(column_datatypes))    # Load a CSV and change relevant columns to bools\n",
    "    \n",
    "    # every #batch_size# file, add it to the df dataframe\n",
    "    if i % batch_size == 0:\n",
    "        df = pd.concat(batch)\n",
    "        batch.clear()   # Get rid of old batch files to free memory\n",
    "        print(f'Loaded to {i}')\n",
    "\n",
    "# Load any remaining data in batch\n",
    "if len(batch) != 0:\n",
    "    print(\"Loading data from final batch.\")\n",
    "    df = pd.concat(batch)\n",
    "\n",
    "clear_output(wait=False)\n",
    "del batch\n",
    "\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a6107541190bd38e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dataframe Memory Size"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d196c76ad9f33c54"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.438190588 gb\n"
     ]
    }
   ],
   "source": [
    "tot_mem = df.memory_usage().sum()\n",
    "print(f'{tot_mem / 1000000000} gb')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T23:51:14.156528600Z",
     "start_time": "2024-04-14T23:51:14.137473100Z"
    }
   },
   "id": "22923238d1d94197"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Encoding labels"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "64aaa3e725257871"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "        flow_duration  Header_Length  Protocol Type  Duration          Rate  \\\n0            0.000000          54.00           6.00     64.00      0.329807   \n1            0.000000          57.04           6.33     64.00      4.290556   \n2            0.000000           0.00           1.00     64.00     33.396799   \n3            0.328175       76175.00          17.00     64.00   4642.133010   \n4            0.117320         101.73           6.11     65.91      6.202211   \n...               ...            ...            ...       ...           ...   \n437357       0.086171       31001.00          17.00     64.00   8560.772402   \n437358       0.000000           0.00          46.53     63.36      2.591956   \n437359       5.636653         108.00           6.00     64.00      0.354820   \n437360       0.000000          54.00           6.00     64.00     18.172690   \n437361       0.024897       16025.00          17.00     64.00  12864.464043   \n\n               Srate  Drate  fin_flag_number  syn_flag_number  \\\n0           0.329807    0.0             True            False   \n1           4.290556    0.0            False            False   \n2          33.396799    0.0            False            False   \n3        4642.133010    0.0            False            False   \n4           6.202211    0.0            False             True   \n...              ...    ...              ...              ...   \n437357   8560.772402    0.0            False            False   \n437358      2.591956    0.0            False            False   \n437359      0.354820    0.0            False             True   \n437360     18.172690    0.0            False            False   \n437361  12864.464043    0.0            False            False   \n\n        rst_flag_number  ...        Std  Tot size           IAT  Number  \\\n0                  True  ...   0.000000     54.00  8.334383e+07     9.5   \n1                 False  ...   2.822973     57.04  8.292607e+07     9.5   \n2                 False  ...   0.000000     42.00  8.312799e+07     9.5   \n3                 False  ...   0.000000     50.00  8.301570e+07     9.5   \n4                 False  ...  23.113111     57.88  8.297300e+07     9.5   \n...                 ...  ...        ...       ...           ...     ...   \n437357            False  ...   0.000000     50.00  8.312382e+07     9.5   \n437358            False  ...   8.802696    586.68  8.368106e+07     9.5   \n437359            False  ...   0.000000     54.00  8.298588e+07     9.5   \n437360            False  ...   0.000000     54.00  8.306725e+07     9.5   \n437361            False  ...   0.000000     50.00  8.301542e+07     9.5   \n\n         Magnitue     Radius   Covariance  Variance  Weight  label  \n0       10.392305   0.000000     0.000000      0.00  141.55      9  \n1       10.464666   4.010353   160.987842      0.05  141.55     20  \n2        9.165151   0.000000     0.000000      0.00  141.55      6  \n3       10.000000   0.000000     0.000000      0.00  141.55     21  \n4       11.346876  32.716243  3016.808286      0.19  141.55     19  \n...           ...        ...          ...       ...     ...    ...  \n437357  10.000000   0.000000     0.000000      0.00  141.55     14  \n437358  34.343416  12.489157  1117.089932      0.07  141.55     23  \n437359  10.392305   0.000000     0.000000      0.00  141.55     19  \n437360  10.392305   0.000000     0.000000      0.00  141.55     13  \n437361  10.000000   0.000000     0.000000      0.00  141.55     21  \n\n[10287724 rows x 47 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>flow_duration</th>\n      <th>Header_Length</th>\n      <th>Protocol Type</th>\n      <th>Duration</th>\n      <th>Rate</th>\n      <th>Srate</th>\n      <th>Drate</th>\n      <th>fin_flag_number</th>\n      <th>syn_flag_number</th>\n      <th>rst_flag_number</th>\n      <th>...</th>\n      <th>Std</th>\n      <th>Tot size</th>\n      <th>IAT</th>\n      <th>Number</th>\n      <th>Magnitue</th>\n      <th>Radius</th>\n      <th>Covariance</th>\n      <th>Variance</th>\n      <th>Weight</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.000000</td>\n      <td>54.00</td>\n      <td>6.00</td>\n      <td>64.00</td>\n      <td>0.329807</td>\n      <td>0.329807</td>\n      <td>0.0</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>54.00</td>\n      <td>8.334383e+07</td>\n      <td>9.5</td>\n      <td>10.392305</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00</td>\n      <td>141.55</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.000000</td>\n      <td>57.04</td>\n      <td>6.33</td>\n      <td>64.00</td>\n      <td>4.290556</td>\n      <td>4.290556</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>2.822973</td>\n      <td>57.04</td>\n      <td>8.292607e+07</td>\n      <td>9.5</td>\n      <td>10.464666</td>\n      <td>4.010353</td>\n      <td>160.987842</td>\n      <td>0.05</td>\n      <td>141.55</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000000</td>\n      <td>0.00</td>\n      <td>1.00</td>\n      <td>64.00</td>\n      <td>33.396799</td>\n      <td>33.396799</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>42.00</td>\n      <td>8.312799e+07</td>\n      <td>9.5</td>\n      <td>9.165151</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00</td>\n      <td>141.55</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.328175</td>\n      <td>76175.00</td>\n      <td>17.00</td>\n      <td>64.00</td>\n      <td>4642.133010</td>\n      <td>4642.133010</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>50.00</td>\n      <td>8.301570e+07</td>\n      <td>9.5</td>\n      <td>10.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00</td>\n      <td>141.55</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.117320</td>\n      <td>101.73</td>\n      <td>6.11</td>\n      <td>65.91</td>\n      <td>6.202211</td>\n      <td>6.202211</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>...</td>\n      <td>23.113111</td>\n      <td>57.88</td>\n      <td>8.297300e+07</td>\n      <td>9.5</td>\n      <td>11.346876</td>\n      <td>32.716243</td>\n      <td>3016.808286</td>\n      <td>0.19</td>\n      <td>141.55</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>437357</th>\n      <td>0.086171</td>\n      <td>31001.00</td>\n      <td>17.00</td>\n      <td>64.00</td>\n      <td>8560.772402</td>\n      <td>8560.772402</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>50.00</td>\n      <td>8.312382e+07</td>\n      <td>9.5</td>\n      <td>10.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00</td>\n      <td>141.55</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>437358</th>\n      <td>0.000000</td>\n      <td>0.00</td>\n      <td>46.53</td>\n      <td>63.36</td>\n      <td>2.591956</td>\n      <td>2.591956</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>8.802696</td>\n      <td>586.68</td>\n      <td>8.368106e+07</td>\n      <td>9.5</td>\n      <td>34.343416</td>\n      <td>12.489157</td>\n      <td>1117.089932</td>\n      <td>0.07</td>\n      <td>141.55</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>437359</th>\n      <td>5.636653</td>\n      <td>108.00</td>\n      <td>6.00</td>\n      <td>64.00</td>\n      <td>0.354820</td>\n      <td>0.354820</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>54.00</td>\n      <td>8.298588e+07</td>\n      <td>9.5</td>\n      <td>10.392305</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00</td>\n      <td>141.55</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>437360</th>\n      <td>0.000000</td>\n      <td>54.00</td>\n      <td>6.00</td>\n      <td>64.00</td>\n      <td>18.172690</td>\n      <td>18.172690</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>54.00</td>\n      <td>8.306725e+07</td>\n      <td>9.5</td>\n      <td>10.392305</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00</td>\n      <td>141.55</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>437361</th>\n      <td>0.024897</td>\n      <td>16025.00</td>\n      <td>17.00</td>\n      <td>64.00</td>\n      <td>12864.464043</td>\n      <td>12864.464043</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>50.00</td>\n      <td>8.301542e+07</td>\n      <td>9.5</td>\n      <td>10.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00</td>\n      <td>141.55</td>\n      <td>21</td>\n    </tr>\n  </tbody>\n</table>\n<p>10287724 rows × 47 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_maps = { 'Backdoor_Malware': 0,         'BenignTraffic': 1,           'BrowserHijacking': 2,\n",
    "               'CommandInjection': 3,         'DDoS-ACK_Fragmentation': 4,  'DDoS-HTTP_Flood': 5,\n",
    "               'DDoS-ICMP_Flood': 6,          'DDoS-ICMP_Fragmentation': 7, 'DDoS-PSHACK_Flood': 8,\n",
    "               'DDoS-RSTFINFlood': 9,         'DDoS-SYN_Flood': 10,         'DDoS-SlowLoris': 11,\n",
    "               'DDoS-SynonymousIP_Flood': 12, 'DDoS-TCP_Flood': 13,         'DDoS-UDP_Flood': 14,\n",
    "               'DDoS-UDP_Fragmentation': 15,  'DNS_Spoofing': 16,           'DictionaryBruteForce': 17,\n",
    "               'DoS-HTTP_Flood': 18,          'DoS-SYN_Flood': 19,          'DoS-TCP_Flood': 20,\n",
    "               'DoS-UDP_Flood': 21,           'MITM-ArpSpoofing': 22,       'Mirai-greeth_flood': 23,\n",
    "               'Mirai-greip_flood': 24,       'Mirai-udpplain': 25,         'Recon-HostDiscovery': 26,\n",
    "               'Recon-OSScan': 27,            'Recon-PingSweep': 28,        'Recon-PortScan': 29,\n",
    "               'SqlInjection': 30,            'Uploading_Attack': 31,       'VulnerabilityScan': 32, \n",
    "               'XSS': 33\n",
    "             }\n",
    "\n",
    "df['label'] = df['label'].map(label_maps)\n",
    "\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T23:51:27.910044400Z",
     "start_time": "2024-04-14T23:51:21.835292Z"
    }
   },
   "id": "5c4230b84755fee9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a6a63563bc6cf116"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Hyper-Parameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27e2bd6be73552dd"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Define the number of neurons in the initial layer of the generator\n",
    "input_shape = 46\n",
    "num_epochs = 2\n",
    "batch_size = 256 # Define your batch size here\n",
    "num_samples = 100\n",
    "epochs = 7000\n",
    "critic_updates = 5  # Number of critic updates per generator update\n",
    "specific_attack_classes = [0, 1, 2, 3, 4 , 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33]\n",
    "num_classes = len(specific_attack_classes)\n",
    "\n",
    "result = df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T23:51:54.147608900Z",
     "start_time": "2024-04-14T23:51:54.121997400Z"
    }
   },
   "id": "51af0bb4842459d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Towson Normal GAN Structure"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "54b3b7de14e652cc"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# GAN class\n",
    "# This class contains the generator and discriminator models, as well as the training loop for the GAN\n",
    "class GAN:\n",
    "    def __init__(self, hidden1, hidden2, hidden3, input_shape, num_classes):\n",
    "        # store the parameters as instance variables\n",
    "        self.hidden1 = hidden1\n",
    "        self.hidden2 = hidden2\n",
    "        self.hidden3 = hidden3\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # build the generator and discriminator\n",
    "        self.generator = self.build_generator(self.hidden1, self.hidden2, self.hidden3, self.input_shape)\n",
    "        self.discriminator = self.build_discriminator()\n",
    "\n",
    "        # compile the generator and discriminator\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "        self.generator.compile(optimizer=optimizer, loss='binary_crossentropy')\n",
    "        self.discriminator.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    def build_generator(self, hidden1, hidden2, hidden3, input_dim):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(hidden1, input_dim=input_dim))  \n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(hidden2))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(hidden3))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(input_dim, activation='relu'))  # Changed from output_dim to input_dim\n",
    "\n",
    "        noise = Input(shape=(input_dim,))\n",
    "        attack = model(noise)\n",
    "        return Model(noise, attack)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(input_shape, input_dim=input_shape, activation='relu'))  \n",
    "        model.add(Dense(30, activation='relu'))\n",
    "        model.add(Dense(15, activation='relu'))\n",
    "        model.add(Dense(1, activation='sigmoid'))  \n",
    "\n",
    "        attack = Input(shape=(input_shape,))\n",
    "        validity = model(attack)\n",
    "\n",
    "        return Model(attack, validity)\n",
    "    \n",
    "   \n",
    "    def discriminator_loss(self, real_output, fake_output):\n",
    "        return tf.reduce_mean(fake_output) - tf.reduce_mean(real_output)\n",
    "\n",
    "    def generator_loss(self, fake_output):\n",
    "        return -tf.reduce_mean(fake_output)\n",
    "\n",
    "\n",
    "    def trainGAN(self, gen_hidden1, gen_hidden2, gen_hidden3, input_dim):\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "        \n",
    "        # Directly use 'result' DataFrame. Ensure it's accessible within this scope.\n",
    "        # Sampling 500 data points randomly from 'result'\n",
    "        sampled_df = result.sample(500)\n",
    "\n",
    "        # Encode labels if not already encoded. Assuming 'label' needs encoding.\n",
    "        # le = LabelEncoder()\n",
    "        # sampled_df['label'] = le.fit_transform(sampled_df['label'])\n",
    "    \n",
    "        # Splitting the data into features and labels\n",
    "        X_train = sampled_df.drop('label', axis=1).values.astype(float)\n",
    "        Y_train = sampled_df['label'].values\n",
    "\n",
    "        # Setting up labels for valid (real) and fake data for training\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "\n",
    "        # Building the discriminator\n",
    "        discriminator = self.build_discriminator()\n",
    "        discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "        # Building the generator\n",
    "        generator = self.build_generator(gen_hidden1, gen_hidden2, gen_hidden3, input_dim)\n",
    "\n",
    "        # Setting up the combined model\n",
    "        z = Input(shape=(input_shape,))\n",
    "        attack = generator(z)\n",
    "        validity = discriminator(attack)\n",
    "        combined = Model(z, validity)\n",
    "        combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            # Train Discriminator\n",
    "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            real_attacks = X_train[idx]\n",
    "\n",
    "            noise = tf.random.normal((batch_size, input_shape))\n",
    "            gen_attacks = generator.predict(noise, training=False)\n",
    "\n",
    "            d_loss_real = discriminator.train_on_batch(real_attacks, valid)\n",
    "            d_loss_fake = discriminator.train_on_batch(gen_attacks, fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # Train Generator\n",
    "            g_loss = combined.train_on_batch(noise, valid)\n",
    "\n",
    "            if epoch % 100 == 0:\n",
    "                print(f\"{epoch} [D loss: {d_loss[0]}, acc.: {100*d_loss[1]}%] [G loss: {g_loss}]\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T23:53:37.565461200Z",
     "start_time": "2024-04-14T23:53:37.534851700Z"
    }
   },
   "id": "e440bc51ca32170f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### GAN Setup & Training Prep"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "26106e7d66f68152"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layers:  100 20 40\n"
     ]
    }
   ],
   "source": [
    "# le = LabelEncoder()\n",
    "# result['label'] = le.fit_transform(result['label'])\n",
    "\n",
    "# Randomly select hidden layer sizes for the generator\n",
    "gen_hidden1 = np.random.randint(1, 101)\n",
    "gen_hidden2 = np.random.randint(1, 101)\n",
    "gen_hidden3 = np.random.randint(1, 101)\n",
    "\n",
    "# Create the GAN with the selected hidden layer sizes\n",
    "gan = GAN(gen_hidden1, gen_hidden2, gen_hidden3, input_shape, num_classes)\n",
    "\n",
    "clear_output(wait=False)\n",
    "\n",
    "print(\"Hidden Layers: \", gen_hidden1, gen_hidden2, gen_hidden3)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "82b6150bc0837309"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# RUN GAN Training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bd6995f4eee9f52c"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training GAN with hidden layers:  100 20 40\n",
      "Training Complete in 976.24 seconds!!!\n"
     ]
    }
   ],
   "source": [
    "# Call the trainGAN function directly to start training\n",
    "print(\"Training GAN with hidden layers: \", gen_hidden1, gen_hidden2, gen_hidden3)\n",
    "\n",
    "# Start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "gan.trainGAN(gen_hidden1, gen_hidden2, gen_hidden3, input_shape)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "clear_output(wait=False)\n",
    "print(\"Training GAN with hidden layers: \", gen_hidden1, gen_hidden2, gen_hidden3)\n",
    "print(\"Training Complete in {:.2f} seconds!!!\".format(end_time - start_time))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b38ec80b1a28cac2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training Evaluation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d4f19b5928dd91b7"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def getAccuracies()  :\n",
    "    accuracy_scores = []\n",
    "    f1_scores = []\n",
    "    for i in range(100) :\n",
    "        # Generate samples from the trained generator\n",
    "        noise = tf.random.normal((num_samples, input_shape))\n",
    "        generated_samples = gan.generator(noise)\n",
    "\n",
    "        # Pass the generated samples through the discriminator\n",
    "        discriminator_predictions = gan.discriminator.predict(generated_samples)\n",
    "\n",
    "        # The ideal output for generated samples is 1\n",
    "        ideal_output = np.ones((num_samples,))\n",
    "\n",
    "        # Correcting the prediction rounding\n",
    "        discriminator_predictions_rounded = np.round(discriminator_predictions).flatten()\n",
    "\n",
    "        # Now, calculating the accuracy should not throw an error\n",
    "        accuracy = accuracy_score(ideal_output, discriminator_predictions_rounded)\n",
    "        f1 = f1_score(ideal_output, discriminator_predictions_rounded)\n",
    "        accuracy_scores.append(accuracy)\n",
    "        f1_scores.append(f1)\n",
    "    \n",
    "    accuracy = np.mean(accuracy_scores)\n",
    "    f1 = np.mean(f1_scores)\n",
    "    return accuracy, f1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T00:10:54.278803900Z",
     "start_time": "2024-04-15T00:10:54.226145500Z"
    }
   },
   "id": "6995ec92cf76edf9"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.0035000000000000005\n",
      "F1 Score:  0.006911279363230441\n"
     ]
    }
   ],
   "source": [
    "accuracy,f1 = getAccuracies()\n",
    "\n",
    "clear_output(wait=False)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"F1 Score: \", f1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "42fa4db54138ec5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Save Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f6e6d9c140d7dff"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/generator\\assets\n",
      "INFO:tensorflow:Assets written to: ../model/discriminator\\assets\n"
     ]
    }
   ],
   "source": [
    "generator_save_path = \"../model/generator\"\n",
    "discriminator_save_path = \"../model/discriminator\"\n",
    "\n",
    "# Save the generator\n",
    "gan.generator.save(generator_save_path)\n",
    "# Save the discriminator\n",
    "gan.discriminator.save(discriminator_save_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T22:46:40.824401800Z",
     "start_time": "2024-04-14T22:46:38.077787300Z"
    }
   },
   "id": "abe8ec4c379f2369"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f6a9e36b9e08ee5f"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 46)]              0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 46)                16663     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,663\n",
      "Trainable params: 16,251\n",
      "Non-trainable params: 412\n",
      "_________________________________________________________________\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 46)]              0         \n",
      "                                                                 \n",
      " sequential_1 (Sequential)   (None, 1)                 4053      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,053\n",
      "Trainable params: 4,053\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator_load_path = \"../model/generator\"\n",
    "discriminator_load_path = \"../model/discriminator\"\n",
    "\n",
    "gan.generator = load_model(generator_load_path)\n",
    "gan.discriminator = load_model(discriminator_load_path)\n",
    "\n",
    "gan.generator.summary()\n",
    "gan.discriminator.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T22:48:26.996835100Z",
     "start_time": "2024-04-14T22:48:25.275559200Z"
    }
   },
   "id": "3d47a79ec79641d9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test Evaluation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5994216370e2cbc3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Will continue to run until a better model is found"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "35c8dc981fd83dae"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "class Looper:\n",
    "    def random_numbers(self):\n",
    "        gen_hidden1 = np.random.randint(1, 101)\n",
    "        gen_hidden2 = np.random.randint(1, 101)\n",
    "        gen_hidden3 = np.random.randint(1, 101)\n",
    "        return [gen_hidden1, gen_hidden2, gen_hidden3]\n",
    "    \n",
    "    def evaluate(gan):\n",
    "        noise = tf.random.normal((num_samples, input_shape))\n",
    "        generated_samples = gan.generator(noise)\n",
    "        discriminator_predictions = gan.discriminator.predict(generated_samples)\n",
    "        ideal_output = np.ones((num_samples,))\n",
    "        discriminator_predictions_rounded = np.round(discriminator_predictions).flatten()\n",
    "        ideal_output = np.ones((num_samples,))\n",
    "        accuracy = accuracy_score(ideal_output, discriminator_predictions_rounded)\n",
    "        f1 = f1_score(ideal_output, discriminator_predictions_rounded)\n",
    "        return accuracy, f1\n",
    "    \n",
    "    def save(gan):\n",
    "        generator_save_path = \"model/best_generator\"\n",
    "        discriminator_save_path = \"model/best_discriminator\"\n",
    "        gan.generator.save(generator_save_path)\n",
    "        gan.discriminator.save(discriminator_save_path)\n",
    "        \n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T22:48:36.726575100Z",
     "start_time": "2024-04-14T22:48:36.688921400Z"
    }
   },
   "id": "5054a1c9e3dbf41a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Final Reuslt From Experiment"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2fedb5448092be35"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "random_numbers() missing 1 required positional argument: 'self'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[15], line 9\u001B[0m\n\u001B[0;32m      5\u001B[0m     best_accuracy, best_f1 \u001B[38;5;241m=\u001B[39m Looper\u001B[38;5;241m.\u001B[39mevaluate(gan)\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m (\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;66;03m# Randomly select hidden layer sizes for the generator\u001B[39;00m\n\u001B[1;32m----> 9\u001B[0m     [gen_hidden1, gen_hidden2, gen_hidden3] \u001B[38;5;241m=\u001B[39m \u001B[43mLooper\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrandom_numbers\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     11\u001B[0m     \u001B[38;5;66;03m# Create the GAN with the selected hidden layer sizes\u001B[39;00m\n\u001B[0;32m     12\u001B[0m     gan \u001B[38;5;241m=\u001B[39m GAN(gen_hidden1, gen_hidden2, gen_hidden3, input_shape, num_classes)\n",
      "\u001B[1;31mTypeError\u001B[0m: random_numbers() missing 1 required positional argument: 'self'"
     ]
    }
   ],
   "source": [
    "looper = Looper()\n",
    "\n",
    "if gan is None:\n",
    "    best_accuracy = 0\n",
    "    best_f1 = 0\n",
    "else:\n",
    "    best_accuracy, best_f1 = looper.evaluate(gan)\n",
    "\n",
    "while(True):\n",
    "    # Randomly select hidden layer sizes for the generator\n",
    "    [gen_hidden1, gen_hidden2, gen_hidden3] = looper.random_numbers()\n",
    "\n",
    "    # Create the GAN with the selected hidden layer sizes\n",
    "    gan = GAN(gen_hidden1, gen_hidden2, gen_hidden3, input_shape, num_classes)\n",
    "    # Call the trainGAN function directly to start training\n",
    "    gan.trainGAN(gen_hidden1, gen_hidden2, gen_hidden3, input_shape)\n",
    "    accuracy, f1 = getAccuracies(gan)   \n",
    "    print(\"Accuracy: \", accuracy, \"F1 Score: \", f1, \"Hidden Layers: \", gen_hidden1, gen_hidden2, gen_hidden3)\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_f1 = f1\n",
    "        Looper.save(gan)\n",
    "        print(\"Saved New Model\")\n",
    "        break\n",
    "    \n",
    "\n",
    "print(\"Accuracy: \", best_accuracy, \"F1 Score: \", best_f1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T22:48:42.443574600Z",
     "start_time": "2024-04-14T22:48:42.285456700Z"
    }
   },
   "id": "3adfbebb93ec143"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "384c6f2478ba0be7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
