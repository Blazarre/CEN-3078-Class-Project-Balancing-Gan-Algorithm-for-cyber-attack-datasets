{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Running Import Statements and ensuring GPU Support"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "16bc02c3fb613f07"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-16T02:19:31.446278Z",
     "start_time": "2024-04-16T02:19:28.663635Z"
    }
   },
   "source": [
    "# from tensorflow.python.client import device_lib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import glob \n",
    "from IPython.display import clear_output\n",
    "import os \n",
    "import time\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "tf.config.list_physical_devices('GPU')\n",
    "gpu = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpu[0], True)\n",
    "print(gpu[0], \"\\n\")\n",
    "# print(device_lib.list_local_devices())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU') \n",
      "\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "Loading the Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6dbd3b980448fb21"
  },
  {
   "cell_type": "code",
   "source": [
    "rel_path = '/archive/'          # If your dataset is within your python project directory, change this to the relative path to your dataset\n",
    "path = os.getcwd() + rel_path   # If your dataset is somewhere else, change this to that path\n",
    "csv_filepaths = glob.glob(os.path.join(path, \"*.csv\"))  # Makes a list of all CSVs within the directory above\n",
    "\n",
    "csv_filepaths = csv_filepaths[:40]\n",
    "\n",
    "# Features that hold values 0/1.\n",
    "column_datatypes = { 'fin_flag_number': 'bool', 'syn_flag_number': 'bool', 'rst_flag_number': 'bool',\n",
    "                     'psh_flag_number': 'bool', 'ack_flag_number': 'bool', 'ece_flag_number': 'bool',\n",
    "                     'cwr_flag_number': 'bool', \n",
    "                     'HTTP': 'bool', 'HTTPS': 'bool', 'DNS': 'bool', 'Telnet': 'bool', 'SMTP': 'bool',\n",
    "                     'SSH': 'bool',  'IRC': 'bool',   'TCP': 'bool', 'UDP': 'bool',    'DHCP': 'bool',\n",
    "                     'ARP': 'bool',  'ICMP': 'bool',  'IPv': 'bool', 'LLC': 'bool'\n",
    "                   }\n",
    "\n",
    "# Load the first csv file\n",
    "df = pd.read_csv(csv_filepaths[0]).astype(column_datatypes)\n",
    "\n",
    "# Load csv files in 10-file batches \n",
    "batch_size = 10\n",
    "\n",
    "for i in range(1, len(csv_filepaths)):\n",
    "    clear_output(wait=False) # Pretty output\n",
    "    print(f'Loading CSV {i}')\n",
    "    \n",
    "    # First file of each batch, restart the batch list\n",
    "    if i % batch_size == 1:\n",
    "        batch = [df]\n",
    "    \n",
    "    batch.append(pd.read_csv(csv_filepaths[i]).astype(column_datatypes))    # Load a CSV and change relevant columns to bools\n",
    "    \n",
    "    # every #batch_size# file, add it to the df dataframe\n",
    "    if i % batch_size == 0:\n",
    "        df = pd.concat(batch)\n",
    "        batch.clear()   # Get rid of old batch files to free memory\n",
    "        print(f'Loaded to {i}')\n",
    "\n",
    "# Load any remaining data in batch\n",
    "if len(batch) != 0:\n",
    "    print(\"Loading data from final batch.\")\n",
    "    df = pd.concat(batch)\n",
    "\n",
    "clear_output(wait=False)\n",
    "del batch\n",
    "\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a6107541190bd38e",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        flow_duration  Header_Length  Protocol Type  Duration          Rate  \\\n",
       "0            0.000000          54.00           6.00     64.00      0.329807   \n",
       "1            0.000000          57.04           6.33     64.00      4.290556   \n",
       "2            0.000000           0.00           1.00     64.00     33.396799   \n",
       "3            0.328175       76175.00          17.00     64.00   4642.133010   \n",
       "4            0.117320         101.73           6.11     65.91      6.202211   \n",
       "...               ...            ...            ...       ...           ...   \n",
       "437357       0.086171       31001.00          17.00     64.00   8560.772402   \n",
       "437358       0.000000           0.00          46.53     63.36      2.591956   \n",
       "437359       5.636653         108.00           6.00     64.00      0.354820   \n",
       "437360       0.000000          54.00           6.00     64.00     18.172690   \n",
       "437361       0.024897       16025.00          17.00     64.00  12864.464043   \n",
       "\n",
       "               Srate  Drate  fin_flag_number  syn_flag_number  \\\n",
       "0           0.329807    0.0             True            False   \n",
       "1           4.290556    0.0            False            False   \n",
       "2          33.396799    0.0            False            False   \n",
       "3        4642.133010    0.0            False            False   \n",
       "4           6.202211    0.0            False             True   \n",
       "...              ...    ...              ...              ...   \n",
       "437357   8560.772402    0.0            False            False   \n",
       "437358      2.591956    0.0            False            False   \n",
       "437359      0.354820    0.0            False             True   \n",
       "437360     18.172690    0.0            False            False   \n",
       "437361  12864.464043    0.0            False            False   \n",
       "\n",
       "        rst_flag_number  ...        Std  Tot size           IAT  Number  \\\n",
       "0                  True  ...   0.000000     54.00  8.334383e+07     9.5   \n",
       "1                 False  ...   2.822973     57.04  8.292607e+07     9.5   \n",
       "2                 False  ...   0.000000     42.00  8.312799e+07     9.5   \n",
       "3                 False  ...   0.000000     50.00  8.301570e+07     9.5   \n",
       "4                 False  ...  23.113111     57.88  8.297300e+07     9.5   \n",
       "...                 ...  ...        ...       ...           ...     ...   \n",
       "437357            False  ...   0.000000     50.00  8.312382e+07     9.5   \n",
       "437358            False  ...   8.802696    586.68  8.368106e+07     9.5   \n",
       "437359            False  ...   0.000000     54.00  8.298588e+07     9.5   \n",
       "437360            False  ...   0.000000     54.00  8.306725e+07     9.5   \n",
       "437361            False  ...   0.000000     50.00  8.301542e+07     9.5   \n",
       "\n",
       "         Magnitue     Radius   Covariance  Variance  Weight  \\\n",
       "0       10.392305   0.000000     0.000000      0.00  141.55   \n",
       "1       10.464666   4.010353   160.987842      0.05  141.55   \n",
       "2        9.165151   0.000000     0.000000      0.00  141.55   \n",
       "3       10.000000   0.000000     0.000000      0.00  141.55   \n",
       "4       11.346876  32.716243  3016.808286      0.19  141.55   \n",
       "...           ...        ...          ...       ...     ...   \n",
       "437357  10.000000   0.000000     0.000000      0.00  141.55   \n",
       "437358  34.343416  12.489157  1117.089932      0.07  141.55   \n",
       "437359  10.392305   0.000000     0.000000      0.00  141.55   \n",
       "437360  10.392305   0.000000     0.000000      0.00  141.55   \n",
       "437361  10.000000   0.000000     0.000000      0.00  141.55   \n",
       "\n",
       "                     label  \n",
       "0         DDoS-RSTFINFlood  \n",
       "1            DoS-TCP_Flood  \n",
       "2          DDoS-ICMP_Flood  \n",
       "3            DoS-UDP_Flood  \n",
       "4            DoS-SYN_Flood  \n",
       "...                    ...  \n",
       "437357      DDoS-UDP_Flood  \n",
       "437358  Mirai-greeth_flood  \n",
       "437359       DoS-SYN_Flood  \n",
       "437360      DDoS-TCP_Flood  \n",
       "437361       DoS-UDP_Flood  \n",
       "\n",
       "[10287724 rows x 47 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flow_duration</th>\n",
       "      <th>Header_Length</th>\n",
       "      <th>Protocol Type</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Rate</th>\n",
       "      <th>Srate</th>\n",
       "      <th>Drate</th>\n",
       "      <th>fin_flag_number</th>\n",
       "      <th>syn_flag_number</th>\n",
       "      <th>rst_flag_number</th>\n",
       "      <th>...</th>\n",
       "      <th>Std</th>\n",
       "      <th>Tot size</th>\n",
       "      <th>IAT</th>\n",
       "      <th>Number</th>\n",
       "      <th>Magnitue</th>\n",
       "      <th>Radius</th>\n",
       "      <th>Covariance</th>\n",
       "      <th>Variance</th>\n",
       "      <th>Weight</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>64.00</td>\n",
       "      <td>0.329807</td>\n",
       "      <td>0.329807</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.00</td>\n",
       "      <td>8.334383e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>10.392305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>141.55</td>\n",
       "      <td>DDoS-RSTFINFlood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>57.04</td>\n",
       "      <td>6.33</td>\n",
       "      <td>64.00</td>\n",
       "      <td>4.290556</td>\n",
       "      <td>4.290556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>2.822973</td>\n",
       "      <td>57.04</td>\n",
       "      <td>8.292607e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>10.464666</td>\n",
       "      <td>4.010353</td>\n",
       "      <td>160.987842</td>\n",
       "      <td>0.05</td>\n",
       "      <td>141.55</td>\n",
       "      <td>DoS-TCP_Flood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>64.00</td>\n",
       "      <td>33.396799</td>\n",
       "      <td>33.396799</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.00</td>\n",
       "      <td>8.312799e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>9.165151</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>141.55</td>\n",
       "      <td>DDoS-ICMP_Flood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.328175</td>\n",
       "      <td>76175.00</td>\n",
       "      <td>17.00</td>\n",
       "      <td>64.00</td>\n",
       "      <td>4642.133010</td>\n",
       "      <td>4642.133010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.00</td>\n",
       "      <td>8.301570e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>141.55</td>\n",
       "      <td>DoS-UDP_Flood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.117320</td>\n",
       "      <td>101.73</td>\n",
       "      <td>6.11</td>\n",
       "      <td>65.91</td>\n",
       "      <td>6.202211</td>\n",
       "      <td>6.202211</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>23.113111</td>\n",
       "      <td>57.88</td>\n",
       "      <td>8.297300e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>11.346876</td>\n",
       "      <td>32.716243</td>\n",
       "      <td>3016.808286</td>\n",
       "      <td>0.19</td>\n",
       "      <td>141.55</td>\n",
       "      <td>DoS-SYN_Flood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437357</th>\n",
       "      <td>0.086171</td>\n",
       "      <td>31001.00</td>\n",
       "      <td>17.00</td>\n",
       "      <td>64.00</td>\n",
       "      <td>8560.772402</td>\n",
       "      <td>8560.772402</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.00</td>\n",
       "      <td>8.312382e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>141.55</td>\n",
       "      <td>DDoS-UDP_Flood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437358</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>46.53</td>\n",
       "      <td>63.36</td>\n",
       "      <td>2.591956</td>\n",
       "      <td>2.591956</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>8.802696</td>\n",
       "      <td>586.68</td>\n",
       "      <td>8.368106e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>34.343416</td>\n",
       "      <td>12.489157</td>\n",
       "      <td>1117.089932</td>\n",
       "      <td>0.07</td>\n",
       "      <td>141.55</td>\n",
       "      <td>Mirai-greeth_flood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437359</th>\n",
       "      <td>5.636653</td>\n",
       "      <td>108.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>64.00</td>\n",
       "      <td>0.354820</td>\n",
       "      <td>0.354820</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.00</td>\n",
       "      <td>8.298588e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>10.392305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>141.55</td>\n",
       "      <td>DoS-SYN_Flood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437360</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>64.00</td>\n",
       "      <td>18.172690</td>\n",
       "      <td>18.172690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.00</td>\n",
       "      <td>8.306725e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>10.392305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>141.55</td>\n",
       "      <td>DDoS-TCP_Flood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437361</th>\n",
       "      <td>0.024897</td>\n",
       "      <td>16025.00</td>\n",
       "      <td>17.00</td>\n",
       "      <td>64.00</td>\n",
       "      <td>12864.464043</td>\n",
       "      <td>12864.464043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.00</td>\n",
       "      <td>8.301542e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>141.55</td>\n",
       "      <td>DoS-UDP_Flood</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10287724 rows × 47 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dataframe Memory Size"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d196c76ad9f33c54"
  },
  {
   "cell_type": "code",
   "source": [
    "tot_mem = df.memory_usage().sum()\n",
    "print(f'{tot_mem / 1000000000} gb')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T01:37:25.878695Z",
     "start_time": "2024-04-16T01:37:25.864669Z"
    }
   },
   "id": "22923238d1d94197",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.438190588 gb\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "Encoding labels"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "64aaa3e725257871"
  },
  {
   "cell_type": "code",
   "source": [
    "label_maps = { 'Backdoor_Malware': 0,         'BenignTraffic': 1,           'BrowserHijacking': 2,\n",
    "               'CommandInjection': 3,         'DDoS-ACK_Fragmentation': 4,  'DDoS-HTTP_Flood': 5,\n",
    "               'DDoS-ICMP_Flood': 6,          'DDoS-ICMP_Fragmentation': 7, 'DDoS-PSHACK_Flood': 8,\n",
    "               'DDoS-RSTFINFlood': 9,         'DDoS-SYN_Flood': 10,         'DDoS-SlowLoris': 11,\n",
    "               'DDoS-SynonymousIP_Flood': 12, 'DDoS-TCP_Flood': 13,         'DDoS-UDP_Flood': 14,\n",
    "               'DDoS-UDP_Fragmentation': 15,  'DNS_Spoofing': 16,           'DictionaryBruteForce': 17,\n",
    "               'DoS-HTTP_Flood': 18,          'DoS-SYN_Flood': 19,          'DoS-TCP_Flood': 20,\n",
    "               'DoS-UDP_Flood': 21,           'MITM-ArpSpoofing': 22,       'Mirai-greeth_flood': 23,\n",
    "               'Mirai-greip_flood': 24,       'Mirai-udpplain': 25,         'Recon-HostDiscovery': 26,\n",
    "               'Recon-OSScan': 27,            'Recon-PingSweep': 28,        'Recon-PortScan': 29,\n",
    "               'SqlInjection': 30,            'Uploading_Attack': 31,       'VulnerabilityScan': 32, \n",
    "               'XSS': 33\n",
    "             }\n",
    "\n",
    "df['label'] = df['label'].map(label_maps)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T01:37:37.821842Z",
     "start_time": "2024-04-16T01:37:31.496377Z"
    }
   },
   "id": "5c4230b84755fee9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 2.438190588 GB\n",
      "Training set shape: (5143862, 46)\n",
      "Test set shape: (5143862, 46)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a6a63563bc6cf116"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Hyper-Parameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27e2bd6be73552dd"
  },
  {
   "cell_type": "code",
   "source": [
    "# Hyperparameters for the Machine Learning Model or GAN setup\n",
    "\n",
    "# Input shape for the model or the initial layer of the generator\n",
    "input_shape = 46\n",
    "\n",
    "# Training Configuration\n",
    "num_epochs = 2       # Number of training epochs overall (if applicable)\n",
    "batch_size = 256     # Batch size for training\n",
    "epochs = 7000        # Specific to the generator or another component\n",
    "\n",
    "# GAN-specific Parameters\n",
    "critic_updates = 5   # Number of critic updates per generator update in a GAN\n",
    "\n",
    "# Sampling and Class Configuration\n",
    "num_samples = 100    # Number of samples to generate or process\n",
    "specific_attack_classes = [0, 1, 2, 3, 4 , 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33]\n",
    "num_classes = len(specific_attack_classes)  # Total number of unique classes\n",
    "\n",
    "# Display DataFrame (Optional: you can remove this if it was for a check)\n",
    "result = df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T01:43:08.794542Z",
     "start_time": "2024-04-16T01:43:07.583269Z"
    }
   },
   "id": "51af0bb4842459d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        flow_duration  Header_Length  Protocol Type  Duration           Rate  \\\n",
       "70392        0.000000          54.00           6.00     64.00       1.266631   \n",
       "418155       0.000000          54.00           6.00     64.00     453.650791   \n",
       "150998       0.023398        7475.00          17.00     64.00  223140.501064   \n",
       "343621       0.174783       37375.00          17.00     64.00    4275.963291   \n",
       "107530       0.000000          54.00           6.00     64.00      29.362110   \n",
       "...               ...            ...            ...       ...            ...   \n",
       "95149        0.000000           0.00          47.00     64.00       1.551552   \n",
       "46243        0.000000          54.00           6.00     64.00       2.227957   \n",
       "230989       0.030131       12655.50          17.00     64.00   14864.653986   \n",
       "178636       0.000000           0.00           1.00     64.00       6.622594   \n",
       "51390        0.000357          63.28           6.11     63.85    1208.082734   \n",
       "\n",
       "                Srate  Drate  fin_flag_number  syn_flag_number  \\\n",
       "70392        1.266631    0.0            False            False   \n",
       "418155     453.650791    0.0            False            False   \n",
       "150998  223140.501064    0.0            False            False   \n",
       "343621    4275.963291    0.0            False            False   \n",
       "107530      29.362110    0.0            False            False   \n",
       "...               ...    ...              ...              ...   \n",
       "95149        1.551552    0.0            False            False   \n",
       "46243        2.227957    0.0             True            False   \n",
       "230989   14864.653986    0.0            False            False   \n",
       "178636       6.622594    0.0            False            False   \n",
       "51390     1208.082734    0.0            False            False   \n",
       "\n",
       "        rst_flag_number  ...         AVG       Std  Tot size           IAT  \\\n",
       "70392             False  ...   54.000000  0.000000     54.00  8.333105e+07   \n",
       "418155            False  ...   54.000000  0.000000     54.00  8.295575e+07   \n",
       "150998            False  ...   50.000000  0.000000     50.00  8.302853e+07   \n",
       "343621            False  ...   50.000000  0.000000     50.00  8.310643e+07   \n",
       "107530            False  ...   54.000000  0.000000     54.00  8.303713e+07   \n",
       "...                 ...  ...         ...       ...       ...           ...   \n",
       "95149             False  ...  578.000000  0.000000    578.00  8.365108e+07   \n",
       "46243              True  ...   54.000000  0.000000     54.00  8.334940e+07   \n",
       "230989            False  ...   50.000000  0.000000     50.00  8.310228e+07   \n",
       "178636            False  ...   42.000000  0.000000     42.00  8.314976e+07   \n",
       "51390             False  ...   56.549705  7.040016     57.84  8.306744e+07   \n",
       "\n",
       "        Number   Magnitue    Radius  Covariance  Variance  Weight  \n",
       "70392      9.5  10.392305  0.000000    0.000000       0.0  141.55  \n",
       "418155     9.5  10.392305  0.000000    0.000000       0.0  141.55  \n",
       "150998     9.5  10.000000  0.000000    0.000000       0.0  141.55  \n",
       "343621     9.5  10.000000  0.000000    0.000000       0.0  141.55  \n",
       "107530     9.5  10.392305  0.000000    0.000000       0.0  141.55  \n",
       "...        ...        ...       ...         ...       ...     ...  \n",
       "95149      9.5  34.000000  0.000000    0.000000       0.0  141.55  \n",
       "46243      9.5  10.392305  0.000000    0.000000       0.0  141.55  \n",
       "230989     9.5  10.000000  0.000000    0.000000       0.0  141.55  \n",
       "178636     9.5   9.165151  0.000000    0.000000       0.0  141.55  \n",
       "51390      9.5  10.631031  9.980748  135.651996       0.5  141.55  \n",
       "\n",
       "[5143862 rows x 46 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flow_duration</th>\n",
       "      <th>Header_Length</th>\n",
       "      <th>Protocol Type</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Rate</th>\n",
       "      <th>Srate</th>\n",
       "      <th>Drate</th>\n",
       "      <th>fin_flag_number</th>\n",
       "      <th>syn_flag_number</th>\n",
       "      <th>rst_flag_number</th>\n",
       "      <th>...</th>\n",
       "      <th>AVG</th>\n",
       "      <th>Std</th>\n",
       "      <th>Tot size</th>\n",
       "      <th>IAT</th>\n",
       "      <th>Number</th>\n",
       "      <th>Magnitue</th>\n",
       "      <th>Radius</th>\n",
       "      <th>Covariance</th>\n",
       "      <th>Variance</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70392</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>64.00</td>\n",
       "      <td>1.266631</td>\n",
       "      <td>1.266631</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.00</td>\n",
       "      <td>8.333105e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>10.392305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418155</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>64.00</td>\n",
       "      <td>453.650791</td>\n",
       "      <td>453.650791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.00</td>\n",
       "      <td>8.295575e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>10.392305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150998</th>\n",
       "      <td>0.023398</td>\n",
       "      <td>7475.00</td>\n",
       "      <td>17.00</td>\n",
       "      <td>64.00</td>\n",
       "      <td>223140.501064</td>\n",
       "      <td>223140.501064</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.00</td>\n",
       "      <td>8.302853e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343621</th>\n",
       "      <td>0.174783</td>\n",
       "      <td>37375.00</td>\n",
       "      <td>17.00</td>\n",
       "      <td>64.00</td>\n",
       "      <td>4275.963291</td>\n",
       "      <td>4275.963291</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.00</td>\n",
       "      <td>8.310643e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107530</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>64.00</td>\n",
       "      <td>29.362110</td>\n",
       "      <td>29.362110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.00</td>\n",
       "      <td>8.303713e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>10.392305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95149</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>47.00</td>\n",
       "      <td>64.00</td>\n",
       "      <td>1.551552</td>\n",
       "      <td>1.551552</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>578.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>578.00</td>\n",
       "      <td>8.365108e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46243</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>64.00</td>\n",
       "      <td>2.227957</td>\n",
       "      <td>2.227957</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.00</td>\n",
       "      <td>8.334940e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>10.392305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230989</th>\n",
       "      <td>0.030131</td>\n",
       "      <td>12655.50</td>\n",
       "      <td>17.00</td>\n",
       "      <td>64.00</td>\n",
       "      <td>14864.653986</td>\n",
       "      <td>14864.653986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.00</td>\n",
       "      <td>8.310228e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178636</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>64.00</td>\n",
       "      <td>6.622594</td>\n",
       "      <td>6.622594</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.00</td>\n",
       "      <td>8.314976e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>9.165151</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51390</th>\n",
       "      <td>0.000357</td>\n",
       "      <td>63.28</td>\n",
       "      <td>6.11</td>\n",
       "      <td>63.85</td>\n",
       "      <td>1208.082734</td>\n",
       "      <td>1208.082734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>56.549705</td>\n",
       "      <td>7.040016</td>\n",
       "      <td>57.84</td>\n",
       "      <td>8.306744e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>10.631031</td>\n",
       "      <td>9.980748</td>\n",
       "      <td>135.651996</td>\n",
       "      <td>0.5</td>\n",
       "      <td>141.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5143862 rows × 46 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Towson Normal GAN Structure"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "54b3b7de14e652cc"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# GAN class\n",
    "# This class contains the generator and discriminator models, as well as the training loop for the GAN\n",
    "class GAN:\n",
    "    def __init__(self, hidden1, hidden2, hidden3, input_shape, num_classes):\n",
    "        # store the parameters as instance variables\n",
    "        self.hidden1 = hidden1\n",
    "        self.hidden2 = hidden2\n",
    "        self.hidden3 = hidden3\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # build the generator and discriminator\n",
    "        self.generator = self.build_generator(self.hidden1, self.hidden2, self.hidden3, self.input_shape)\n",
    "        self.discriminator = self.build_discriminator()\n",
    "\n",
    "        # setting the loss function for generator and discriminator\n",
    "        self.optimizer = Adam(0.0002, 0.5)\n",
    "        self.generator.compile(optimizer=self.optimizer, loss='categorical_crossentropy')\n",
    "        self.discriminator.compile(optimizer=self.optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    def build_generator(self, hidden1, hidden2, hidden3, input_dim):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(hidden1, input_dim=input_dim))  \n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(hidden2))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(hidden3))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(input_dim, activation='relu'))  # Changed from output_dim to input_dim\n",
    "\n",
    "        noise = Input(shape=(input_dim,))\n",
    "        attack = model(noise)\n",
    "        return Model(noise, attack)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(input_shape, input_dim=input_shape, activation='relu'))  \n",
    "        model.add(Dense(30, activation='relu'))\n",
    "        model.add(Dense(15, activation='relu'))\n",
    "        model.add(Dense(1, activation='sigmoid'))  \n",
    "\n",
    "        attack = Input(shape=(input_shape,))\n",
    "        validity = model(attack)\n",
    "\n",
    "        return Model(attack, validity)\n",
    "    \n",
    "   \n",
    "    def discriminator_loss(self, real_output, fake_output):\n",
    "        return tf.reduce_mean(fake_output) - tf.reduce_mean(real_output)\n",
    "\n",
    "    def generator_loss(self, fake_output):\n",
    "        return tf.reduce_mean(fake_output)\n",
    "\n",
    "\n",
    "    def trainGAN(self, gen_hidden1, gen_hidden2, gen_hidden3, input_dim):\n",
    "        \"\"\"\n",
    "        \n",
    "        :param gen_hidden1: \n",
    "        :param gen_hidden2: \n",
    "        :param gen_hidden3: \n",
    "        :param input_dim: \n",
    "        :return: \n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        Setting up Optimizer\n",
    "        \"\"\"\n",
    "        # optimizer = Adam(0.0002, 0.5)\n",
    "        \n",
    "        \"\"\"\n",
    "        Getting the data\n",
    "        \"\"\"\n",
    "        \n",
    "        # Directly use 'result' DataFrame. Ensure it's accessible within this scope.\n",
    "        # Sampling 500 data points randomly from 'result'\n",
    "        sampled_df = result.sample(1000)\n",
    "        \"\"\"\n",
    "        Redundant Label Encoding\n",
    "        \"\"\"\n",
    "        le = LabelEncoder()\n",
    "        sampled_df['label'] = le.fit_transform(sampled_df['label'])\n",
    "        \n",
    "        \"\"\"\n",
    "        Splitting the data into features and labels\n",
    "        \"\"\"\n",
    "        # Split the data into training and testing sets\n",
    "        X = sampled_df.drop('label', axis=1)  # Features\n",
    "        y = sampled_df['label']               # Target label\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "        \n",
    "        # Output the memory usage and the shapes of training/testing datasets\n",
    "        print(f'Memory usage: {df.memory_usage().sum() / 1000000000} GB')\n",
    "        print('Training set shape:', X_train.shape)\n",
    "        print('Test set shape:', X_test.shape)\n",
    "\n",
    "        \"\"\"\n",
    "        Setting up labels for valid (real) and fake data for training\n",
    "        \"\"\"\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "\n",
    "        \"\"\"\n",
    "        Building the discriminator\n",
    "        \"\"\"\n",
    "        # discriminator = self.build_discriminator()\n",
    "        # discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "        \"\"\"\n",
    "        Building the generator\n",
    "        \"\"\"\n",
    "        # generator = self.build_generator(gen_hidden1, gen_hidden2, gen_hidden3, input_dim)\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        Setting up the combined model\n",
    "        \"\"\"\n",
    "        z = Input(shape=(input_shape,))\n",
    "        attack = self.generator(z)\n",
    "        validity = self.discriminator(attack)\n",
    "        combined = Model(z, validity)\n",
    "        combined.compile(loss='binary_crossentropy', optimizer=self.optimizer)\n",
    "        \n",
    "        \"\"\"\n",
    "        set up of break conditions for training when the generator is worsening\n",
    "        \"\"\"\n",
    "        loss_increase_count = 0\n",
    "        prev_g_loss = 0\n",
    "        \n",
    "        \"\"\"\n",
    "        TRAINING LOOP\n",
    "        \"\"\"\n",
    "        for epoch in range(epochs):\n",
    "            # Get Training Data from X_train\n",
    "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            real_attacks = X_train[idx]\n",
    "\n",
    "            # Run Generator\n",
    "            noise = tf.random.normal((batch_size, input_shape))  # Make the noise input\n",
    "            gen_attacks = self.generator.predict(noise, training=False)  # Make the synthetic data\n",
    "            \n",
    "            # Train Discriminator with training data and synthetic data\n",
    "            d_loss_real = self.discriminator.train_on_batch(real_attacks, valid)\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_attacks, fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # Train Generator from the noise and valid label by using the combined model to have the generator interact with the discriminator\n",
    "            g_loss = combined.train_on_batch(noise, valid)\n",
    "            \n",
    "            # at the end of 100 epochs print the losses and accuracy\n",
    "            if epoch % 100 == 0:\n",
    "                print(f\"{epoch} [D loss: {d_loss[0]}, acc.: {100*d_loss[1]}%] [G loss: {g_loss}]\")\n",
    "            \n",
    "            # if the loss is greater than previous loss then increase the counter \n",
    "            if (g_loss - prev_g_loss) > 0: \n",
    "                loss_increase_count = loss_increase_count + 1\n",
    "            else: \n",
    "                loss_increase_count = 0  # otherwise, reset it to 0, we are still training effectively\n",
    "                \n",
    "            prev_g_loss = g_loss\n",
    "            \n",
    "            # Conditions to stop the loop if generator loss increases 5 times    \n",
    "            if loss_increase_count > 5:\n",
    "                print('Stoping on iteration: ', epoch)\n",
    "                break\n",
    "            \n",
    "            # saving the generated output\n",
    "            if epoch % 20 == 0:\n",
    "                f = open(\"/Results/GeneratedAttackResults.txt\", \"a\")\n",
    "                np.savetxt(\"/Results/GeneratedAttackResults.txt\", gen_attacks, fmt=\"%.0f\")\n",
    "                f.close()\n",
    "\n",
    "        # peek at our results\n",
    "        results = np.loadtxt(\"/Results/GeneratedResults.txt\")  # save final output\n",
    "        print(\"Generated attacks: \")\n",
    "        print(results[:2])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T21:44:22.385796800Z",
     "start_time": "2024-04-15T21:44:22.369787300Z"
    }
   },
   "id": "e440bc51ca32170f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### GAN Setup & Training Prep"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "26106e7d66f68152"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layers:  62 72 89\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Randomly select hidden layer sizes for the generator\n",
    "gen_hidden1 = np.random.randint(1, 101)\n",
    "gen_hidden2 = np.random.randint(1, 101)\n",
    "gen_hidden3 = np.random.randint(1, 101)\n",
    "\n",
    "# Create the GAN with the selected hidden layer sizes\n",
    "gan = GAN(gen_hidden1, gen_hidden2, gen_hidden3, input_shape, num_classes)\n",
    "\n",
    "clear_output(wait=False)\n",
    "\n",
    "print(\"Hidden Layers: \", gen_hidden1, gen_hidden2, gen_hidden3)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "82b6150bc0837309"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# RUN GAN Training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bd6995f4eee9f52c"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training GAN with hidden layers:  62 72 89\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "0 [D loss: 1803544.879536599, acc.: 4.1015625%] [G loss: 0.5822311043739319]\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 1000us/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "100 [D loss: 0.5265399217605591, acc.: 50.1953125%] [G loss: 0.45963364839553833]\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1000us/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 999us/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1000us/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1000us/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1000us/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1000us/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 999us/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "200 [D loss: 0.4583108730254451, acc.: 54.4921875%] [G loss: 0.544391393661499]\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 929us/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 999us/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[19], line 7\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# Start the timer\u001B[39;00m\n\u001B[0;32m      5\u001B[0m start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m----> 7\u001B[0m \u001B[43mgan\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrainGAN\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgen_hidden1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgen_hidden2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgen_hidden3\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_shape\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m end_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m     11\u001B[0m clear_output(wait\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "Cell \u001B[1;32mIn[17], line 133\u001B[0m, in \u001B[0;36mGAN.trainGAN\u001B[1;34m(self, gen_hidden1, gen_hidden2, gen_hidden3, input_dim)\u001B[0m\n\u001B[0;32m    131\u001B[0m \u001B[38;5;66;03m# run the generator\u001B[39;00m\n\u001B[0;32m    132\u001B[0m noise \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mnormal((batch_size, input_shape))\n\u001B[1;32m--> 133\u001B[0m gen_attacks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnoise\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    135\u001B[0m \u001B[38;5;66;03m# get the discriminator loss\u001B[39;00m\n\u001B[0;32m    136\u001B[0m d_loss_real \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdiscriminator\u001B[38;5;241m.\u001B[39mtrain_on_batch(real_attacks, valid)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\TensorflowENV2\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\TensorflowENV2\\lib\\site-packages\\keras\\engine\\training.py:2220\u001B[0m, in \u001B[0;36mModel.predict\u001B[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   2211\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m:\n\u001B[0;32m   2212\u001B[0m         warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m   2213\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUsing Model.predict with MultiWorkerMirroredStrategy \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2214\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mor TPUStrategy and AutoShardPolicy.FILE might lead to \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   2217\u001B[0m             stacklevel\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m,\n\u001B[0;32m   2218\u001B[0m         )\n\u001B[1;32m-> 2220\u001B[0m data_handler \u001B[38;5;241m=\u001B[39m \u001B[43mdata_adapter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_data_handler\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2221\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2222\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2223\u001B[0m \u001B[43m    \u001B[49m\u001B[43msteps_per_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msteps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2224\u001B[0m \u001B[43m    \u001B[49m\u001B[43minitial_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2225\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2226\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_queue_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_queue_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2227\u001B[0m \u001B[43m    \u001B[49m\u001B[43mworkers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mworkers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2228\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_multiprocessing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_multiprocessing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2229\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2230\u001B[0m \u001B[43m    \u001B[49m\u001B[43msteps_per_execution\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_steps_per_execution\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2231\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2233\u001B[0m \u001B[38;5;66;03m# Container that configures and calls `tf.keras.Callback`s.\u001B[39;00m\n\u001B[0;32m   2234\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(callbacks, callbacks_module\u001B[38;5;241m.\u001B[39mCallbackList):\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\TensorflowENV2\\lib\\site-packages\\keras\\engine\\data_adapter.py:1582\u001B[0m, in \u001B[0;36mget_data_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m   1580\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m], \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_cluster_coordinator\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m   1581\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _ClusterCoordinatorDataHandler(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m-> 1582\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m DataHandler(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\TensorflowENV2\\lib\\site-packages\\keras\\engine\\data_adapter.py:1262\u001B[0m, in \u001B[0;36mDataHandler.__init__\u001B[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001B[0m\n\u001B[0;32m   1259\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_steps_per_execution \u001B[38;5;241m=\u001B[39m steps_per_execution\n\u001B[0;32m   1261\u001B[0m adapter_cls \u001B[38;5;241m=\u001B[39m select_data_adapter(x, y)\n\u001B[1;32m-> 1262\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_adapter \u001B[38;5;241m=\u001B[39m \u001B[43madapter_cls\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1263\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1264\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1265\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1266\u001B[0m \u001B[43m    \u001B[49m\u001B[43msteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msteps_per_epoch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1267\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[43minitial_epoch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1268\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_weights\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1269\u001B[0m \u001B[43m    \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshuffle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1270\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_queue_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_queue_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1271\u001B[0m \u001B[43m    \u001B[49m\u001B[43mworkers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mworkers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1272\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_multiprocessing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_multiprocessing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1273\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdistribution_strategy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdistribute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_strategy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1274\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1275\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1277\u001B[0m strategy \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mdistribute\u001B[38;5;241m.\u001B[39mget_strategy()\n\u001B[0;32m   1279\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_current_step \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\TensorflowENV2\\lib\\site-packages\\keras\\engine\\data_adapter.py:349\u001B[0m, in \u001B[0;36mTensorLikeDataAdapter.__init__\u001B[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001B[0m\n\u001B[0;32m    345\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m flat_dataset\n\u001B[0;32m    347\u001B[0m indices_dataset \u001B[38;5;241m=\u001B[39m indices_dataset\u001B[38;5;241m.\u001B[39mflat_map(slice_batch_indices)\n\u001B[1;32m--> 349\u001B[0m dataset \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mslice_inputs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindices_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    351\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m shuffle \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbatch\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    353\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mshuffle_batch\u001B[39m(\u001B[38;5;241m*\u001B[39mbatch):\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\TensorflowENV2\\lib\\site-packages\\keras\\engine\\data_adapter.py:390\u001B[0m, in \u001B[0;36mTensorLikeDataAdapter.slice_inputs\u001B[1;34m(self, indices_dataset, inputs)\u001B[0m\n\u001B[0;32m    385\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mgrab_batch\u001B[39m(i, data):\n\u001B[0;32m    386\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mnest\u001B[38;5;241m.\u001B[39mmap_structure(\n\u001B[0;32m    387\u001B[0m         \u001B[38;5;28;01mlambda\u001B[39;00m d: tf\u001B[38;5;241m.\u001B[39mgather(d, i, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m), data\n\u001B[0;32m    388\u001B[0m     )\n\u001B[1;32m--> 390\u001B[0m dataset \u001B[38;5;241m=\u001B[39m \u001B[43mdataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgrab_batch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_parallel_calls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mAUTOTUNE\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    392\u001B[0m \u001B[38;5;66;03m# Default optimizations are disabled to avoid the overhead of\u001B[39;00m\n\u001B[0;32m    393\u001B[0m \u001B[38;5;66;03m# (unnecessary) input pipeline graph serialization and deserialization\u001B[39;00m\n\u001B[0;32m    394\u001B[0m options \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mOptions()\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\TensorflowENV2\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:2204\u001B[0m, in \u001B[0;36mDatasetV2.map\u001B[1;34m(self, map_func, num_parallel_calls, deterministic, name)\u001B[0m\n\u001B[0;32m   2202\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m MapDataset(\u001B[38;5;28mself\u001B[39m, map_func, preserve_cardinality\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, name\u001B[38;5;241m=\u001B[39mname)\n\u001B[0;32m   2203\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 2204\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mParallelMapDataset\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2205\u001B[0m \u001B[43m      \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2206\u001B[0m \u001B[43m      \u001B[49m\u001B[43mmap_func\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2207\u001B[0m \u001B[43m      \u001B[49m\u001B[43mnum_parallel_calls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2208\u001B[0m \u001B[43m      \u001B[49m\u001B[43mdeterministic\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2209\u001B[0m \u001B[43m      \u001B[49m\u001B[43mpreserve_cardinality\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   2210\u001B[0m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\TensorflowENV2\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:5456\u001B[0m, in \u001B[0;36mParallelMapDataset.__init__\u001B[1;34m(self, input_dataset, map_func, num_parallel_calls, deterministic, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001B[0m\n\u001B[0;32m   5453\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_parallel_calls \u001B[38;5;241m=\u001B[39m ops\u001B[38;5;241m.\u001B[39mconvert_to_tensor(\n\u001B[0;32m   5454\u001B[0m     num_parallel_calls, dtype\u001B[38;5;241m=\u001B[39mdtypes\u001B[38;5;241m.\u001B[39mint64, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnum_parallel_calls\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   5455\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_name \u001B[38;5;241m=\u001B[39m name\n\u001B[1;32m-> 5456\u001B[0m variant_tensor \u001B[38;5;241m=\u001B[39m gen_dataset_ops\u001B[38;5;241m.\u001B[39mparallel_map_dataset_v2(\n\u001B[0;32m   5457\u001B[0m     input_dataset\u001B[38;5;241m.\u001B[39m_variant_tensor,  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[0;32m   5458\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_map_func\u001B[38;5;241m.\u001B[39mfunction\u001B[38;5;241m.\u001B[39mcaptured_inputs,\n\u001B[0;32m   5459\u001B[0m     f\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_map_func\u001B[38;5;241m.\u001B[39mfunction,\n\u001B[0;32m   5460\u001B[0m     num_parallel_calls\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_parallel_calls,\n\u001B[0;32m   5461\u001B[0m     deterministic\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_deterministic,\n\u001B[0;32m   5462\u001B[0m     use_inter_op_parallelism\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_use_inter_op_parallelism,\n\u001B[0;32m   5463\u001B[0m     preserve_cardinality\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_preserve_cardinality,\n\u001B[0;32m   5464\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_common_args)\n\u001B[0;32m   5465\u001B[0m \u001B[38;5;28msuper\u001B[39m(ParallelMapDataset, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(input_dataset, variant_tensor)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\TensorflowENV2\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:6023\u001B[0m, in \u001B[0;36mparallel_map_dataset_v2\u001B[1;34m(input_dataset, other_arguments, num_parallel_calls, f, output_types, output_shapes, use_inter_op_parallelism, deterministic, preserve_cardinality, metadata, name)\u001B[0m\n\u001B[0;32m   6021\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tld\u001B[38;5;241m.\u001B[39mis_eager:\n\u001B[0;32m   6022\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 6023\u001B[0m     _result \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_FastPathExecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   6024\u001B[0m \u001B[43m      \u001B[49m\u001B[43m_ctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mParallelMapDatasetV2\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mother_arguments\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   6025\u001B[0m \u001B[43m      \u001B[49m\u001B[43mnum_parallel_calls\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43moutput_types\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_types\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   6026\u001B[0m \u001B[43m      \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43moutput_shapes\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_shapes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43muse_inter_op_parallelism\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   6027\u001B[0m \u001B[43m      \u001B[49m\u001B[43muse_inter_op_parallelism\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdeterministic\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdeterministic\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   6028\u001B[0m \u001B[43m      \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpreserve_cardinality\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpreserve_cardinality\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmetadata\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   6029\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _result\n\u001B[0;32m   6030\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m _core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Call the trainGAN function directly to start training\n",
    "print(\"Training GAN with hidden layers: \", gen_hidden1, gen_hidden2, gen_hidden3)\n",
    "\n",
    "# Start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "gan.trainGAN(gen_hidden1, gen_hidden2, gen_hidden3, input_shape)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "clear_output(wait=False)\n",
    "print(\"Training GAN with hidden layers: \", gen_hidden1, gen_hidden2, gen_hidden3)\n",
    "print(\"Training Complete in {:.2f} seconds!!!\".format(end_time - start_time))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T21:44:54.438751600Z",
     "start_time": "2024-04-15T21:44:33.580459600Z"
    }
   },
   "id": "b38ec80b1a28cac2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training Evaluation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d4f19b5928dd91b7"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def getAccuracies()  :\n",
    "    accuracy_scores = []\n",
    "    f1_scores = []\n",
    "    for i in range(100) :\n",
    "        # Generate samples from the trained generator\n",
    "        noise = tf.random.normal((num_samples, input_shape))\n",
    "        generated_samples = gan.generator(noise)\n",
    "\n",
    "        # Pass the generated samples through the discriminator\n",
    "        discriminator_predictions = gan.discriminator.predict(generated_samples)\n",
    "\n",
    "        # The ideal output for generated samples is 1\n",
    "        ideal_output = np.ones((num_samples,))\n",
    "\n",
    "        # Correcting the prediction rounding\n",
    "        discriminator_predictions_rounded = np.round(discriminator_predictions).flatten()\n",
    "\n",
    "        # Now, calculating the accuracy should not throw an error\n",
    "        accuracy = accuracy_score(ideal_output, discriminator_predictions_rounded)\n",
    "        f1 = f1_score(ideal_output, discriminator_predictions_rounded)\n",
    "        accuracy_scores.append(accuracy)\n",
    "        f1_scores.append(f1)\n",
    "    \n",
    "    accuracy = np.mean(accuracy_scores)\n",
    "    f1 = np.mean(f1_scores)\n",
    "    return accuracy, f1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T20:00:52.718395Z",
     "start_time": "2024-04-15T20:00:52.700856300Z"
    }
   },
   "id": "6995ec92cf76edf9"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.13620000000000002\n",
      "F1 Score:  0.23805341747768885\n"
     ]
    }
   ],
   "source": [
    "accuracy,f1 = getAccuracies()\n",
    "\n",
    "clear_output(wait=False)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"F1 Score: \", f1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "42fa4db54138ec5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Save Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f6e6d9c140d7dff"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/generator\\assets\n",
      "INFO:tensorflow:Assets written to: ../model/discriminator\\assets\n"
     ]
    }
   ],
   "source": [
    "generator_save_path = \"/model/generator\"\n",
    "discriminator_save_path = \"/model/discriminator\"\n",
    "\n",
    "# Save the generator\n",
    "gan.generator.save(generator_save_path)\n",
    "# Save the discriminator\n",
    "gan.discriminator.save(discriminator_save_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T20:01:10.850867200Z",
     "start_time": "2024-04-15T20:01:09.449407500Z"
    }
   },
   "id": "abe8ec4c379f2369"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f6a9e36b9e08ee5f"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 46)]              0         \n",
      "                                                                 \n",
      " sequential_6 (Sequential)   (None, 46)                3883      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,883\n",
      "Trainable params: 3,739\n",
      "Non-trainable params: 144\n",
      "_________________________________________________________________\n",
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_10 (InputLayer)       [(None, 46)]              0         \n",
      "                                                                 \n",
      " sequential_7 (Sequential)   (None, 1)                 4053      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,053\n",
      "Trainable params: 4,053\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator_load_path = \"../model/generator\"\n",
    "discriminator_load_path = \"../model/discriminator\"\n",
    "\n",
    "gan.generator = load_model(generator_load_path)\n",
    "gan.discriminator = load_model(discriminator_load_path)\n",
    "\n",
    "gan.generator.summary()\n",
    "gan.discriminator.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T20:01:15.290120700Z",
     "start_time": "2024-04-15T20:01:14.518427900Z"
    }
   },
   "id": "3d47a79ec79641d9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test Evaluation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5994216370e2cbc3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Will continue to run until a better model is found"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "35c8dc981fd83dae"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "class Looper:\n",
    "    def random_numbers(self):\n",
    "        gen_hidden1 = np.random.randint(1, 101)\n",
    "        gen_hidden2 = np.random.randint(1, 101)\n",
    "        gen_hidden3 = np.random.randint(1, 101)\n",
    "        return [gen_hidden1, gen_hidden2, gen_hidden3]\n",
    "    \n",
    "    def evaluate(gan):\n",
    "        noise = tf.random.normal((num_samples, input_shape))\n",
    "        generated_samples = gan.generator(noise)\n",
    "        discriminator_predictions = gan.discriminator.predict(generated_samples)\n",
    "        ideal_output = np.ones((num_samples,))\n",
    "        discriminator_predictions_rounded = np.round(discriminator_predictions).flatten()\n",
    "        ideal_output = np.ones((num_samples,))\n",
    "        accuracy = accuracy_score(ideal_output, discriminator_predictions_rounded)\n",
    "        f1 = f1_score(ideal_output, discriminator_predictions_rounded)\n",
    "        return accuracy, f1\n",
    "    \n",
    "    def save(gan):\n",
    "        generator_save_path = \"model/best_generator\"\n",
    "        discriminator_save_path = \"model/best_discriminator\"\n",
    "        gan.generator.save(generator_save_path)\n",
    "        gan.discriminator.save(discriminator_save_path)\n",
    "        \n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T22:48:36.726575100Z",
     "start_time": "2024-04-14T22:48:36.688921400Z"
    }
   },
   "id": "5054a1c9e3dbf41a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Final Reuslt From Experiment"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2fedb5448092be35"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "random_numbers() missing 1 required positional argument: 'self'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[15], line 9\u001B[0m\n\u001B[0;32m      5\u001B[0m     best_accuracy, best_f1 \u001B[38;5;241m=\u001B[39m Looper\u001B[38;5;241m.\u001B[39mevaluate(gan)\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m (\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;66;03m# Randomly select hidden layer sizes for the generator\u001B[39;00m\n\u001B[1;32m----> 9\u001B[0m     [gen_hidden1, gen_hidden2, gen_hidden3] \u001B[38;5;241m=\u001B[39m \u001B[43mLooper\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrandom_numbers\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     11\u001B[0m     \u001B[38;5;66;03m# Create the GAN with the selected hidden layer sizes\u001B[39;00m\n\u001B[0;32m     12\u001B[0m     gan \u001B[38;5;241m=\u001B[39m GAN(gen_hidden1, gen_hidden2, gen_hidden3, input_shape, num_classes)\n",
      "\u001B[1;31mTypeError\u001B[0m: random_numbers() missing 1 required positional argument: 'self'"
     ]
    }
   ],
   "source": [
    "looper = Looper()\n",
    "\n",
    "if gan is None:\n",
    "    best_accuracy = 0\n",
    "    best_f1 = 0\n",
    "else:\n",
    "    best_accuracy, best_f1 = looper.evaluate(gan)\n",
    "\n",
    "while(True):\n",
    "    # Randomly select hidden layer sizes for the generator\n",
    "    [gen_hidden1, gen_hidden2, gen_hidden3] = looper.random_numbers()\n",
    "\n",
    "    # Create the GAN with the selected hidden layer sizes\n",
    "    gan = GAN(gen_hidden1, gen_hidden2, gen_hidden3, input_shape, num_classes)\n",
    "    # Call the trainGAN function directly to start training\n",
    "    gan.trainGAN(gen_hidden1, gen_hidden2, gen_hidden3, input_shape)\n",
    "    accuracy, f1 = getAccuracies(gan)   \n",
    "    print(\"Accuracy: \", accuracy, \"F1 Score: \", f1, \"Hidden Layers: \", gen_hidden1, gen_hidden2, gen_hidden3)\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_f1 = f1\n",
    "        Looper.save(gan)\n",
    "        print(\"Saved New Model\")\n",
    "        break\n",
    "    \n",
    "\n",
    "print(\"Accuracy: \", best_accuracy, \"F1 Score: \", best_f1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T22:48:42.443574600Z",
     "start_time": "2024-04-14T22:48:42.285456700Z"
    }
   },
   "id": "3adfbebb93ec143"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "384c6f2478ba0be7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
